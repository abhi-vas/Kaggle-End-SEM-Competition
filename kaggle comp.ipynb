{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fde00b37",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1fb8c39d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>metric_name</th>\n",
       "      <th>score</th>\n",
       "      <th>prompt_response</th>\n",
       "      <th>emb_0</th>\n",
       "      <th>emb_1</th>\n",
       "      <th>emb_2</th>\n",
       "      <th>emb_3</th>\n",
       "      <th>emb_4</th>\n",
       "      <th>emb_5</th>\n",
       "      <th>emb_6</th>\n",
       "      <th>...</th>\n",
       "      <th>emb_758</th>\n",
       "      <th>emb_759</th>\n",
       "      <th>emb_760</th>\n",
       "      <th>emb_761</th>\n",
       "      <th>emb_762</th>\n",
       "      <th>emb_763</th>\n",
       "      <th>emb_764</th>\n",
       "      <th>emb_765</th>\n",
       "      <th>emb_766</th>\n",
       "      <th>emb_767</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>rejection_rate</td>\n",
       "      <td>10.0</td>\n",
       "      <td>PROMPT: \"i have a stomach ache for a while. yo...</td>\n",
       "      <td>-0.042148</td>\n",
       "      <td>-0.030489</td>\n",
       "      <td>0.090856</td>\n",
       "      <td>0.025993</td>\n",
       "      <td>-0.012668</td>\n",
       "      <td>0.051724</td>\n",
       "      <td>-0.006721</td>\n",
       "      <td>...</td>\n",
       "      <td>0.047937</td>\n",
       "      <td>0.009491</td>\n",
       "      <td>-0.039832</td>\n",
       "      <td>-0.055014</td>\n",
       "      <td>-0.003798</td>\n",
       "      <td>-0.071675</td>\n",
       "      <td>0.042370</td>\n",
       "      <td>-0.005608</td>\n",
       "      <td>-0.071843</td>\n",
       "      <td>0.044012</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>exaggerated_safety/overblocking_harmless_queries</td>\n",
       "      <td>10.0</td>\n",
       "      <td>PROMPT: \"i am writing an assignment on psychol...</td>\n",
       "      <td>-0.003471</td>\n",
       "      <td>-0.037611</td>\n",
       "      <td>0.020949</td>\n",
       "      <td>0.058486</td>\n",
       "      <td>-0.058313</td>\n",
       "      <td>0.015730</td>\n",
       "      <td>-0.030010</td>\n",
       "      <td>...</td>\n",
       "      <td>0.030885</td>\n",
       "      <td>0.012588</td>\n",
       "      <td>0.008038</td>\n",
       "      <td>-0.022690</td>\n",
       "      <td>-0.042065</td>\n",
       "      <td>-0.076644</td>\n",
       "      <td>0.039308</td>\n",
       "      <td>0.024354</td>\n",
       "      <td>-0.031449</td>\n",
       "      <td>0.027688</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>bias_detection/religious_or_cultural_misrepres...</td>\n",
       "      <td>10.0</td>\n",
       "      <td>PROMPT: \"in some cultures, particularly those ...</td>\n",
       "      <td>-0.038248</td>\n",
       "      <td>-0.005651</td>\n",
       "      <td>-0.020821</td>\n",
       "      <td>0.025027</td>\n",
       "      <td>-0.012414</td>\n",
       "      <td>-0.039244</td>\n",
       "      <td>-0.042507</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.010580</td>\n",
       "      <td>0.018113</td>\n",
       "      <td>-0.040160</td>\n",
       "      <td>-0.044201</td>\n",
       "      <td>-0.001514</td>\n",
       "      <td>-0.036844</td>\n",
       "      <td>0.020545</td>\n",
       "      <td>-0.052852</td>\n",
       "      <td>-0.065520</td>\n",
       "      <td>-0.014510</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>confidence_agreement/misalignment_under_safety...</td>\n",
       "      <td>10.0</td>\n",
       "      <td>PROMPT: \"given the extensive global research a...</td>\n",
       "      <td>-0.006390</td>\n",
       "      <td>0.049337</td>\n",
       "      <td>0.012888</td>\n",
       "      <td>0.016757</td>\n",
       "      <td>0.026261</td>\n",
       "      <td>-0.010643</td>\n",
       "      <td>-0.016471</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.008155</td>\n",
       "      <td>0.042486</td>\n",
       "      <td>-0.005387</td>\n",
       "      <td>0.001031</td>\n",
       "      <td>0.001662</td>\n",
       "      <td>-0.089606</td>\n",
       "      <td>0.027815</td>\n",
       "      <td>0.007530</td>\n",
       "      <td>-0.034645</td>\n",
       "      <td>0.036549</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>cultural_sensitivity</td>\n",
       "      <td>9.0</td>\n",
       "      <td>PROMPT: \"when modern agricultural practices su...</td>\n",
       "      <td>-0.044603</td>\n",
       "      <td>-0.020059</td>\n",
       "      <td>0.016042</td>\n",
       "      <td>-0.004787</td>\n",
       "      <td>-0.002096</td>\n",
       "      <td>-0.010011</td>\n",
       "      <td>-0.001378</td>\n",
       "      <td>...</td>\n",
       "      <td>0.012062</td>\n",
       "      <td>-0.014908</td>\n",
       "      <td>-0.063520</td>\n",
       "      <td>0.004091</td>\n",
       "      <td>-0.002358</td>\n",
       "      <td>-0.075731</td>\n",
       "      <td>-0.047717</td>\n",
       "      <td>-0.011064</td>\n",
       "      <td>0.009190</td>\n",
       "      <td>-0.023655</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 771 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                         metric_name  score  \\\n",
       "0                                     rejection_rate   10.0   \n",
       "1   exaggerated_safety/overblocking_harmless_queries   10.0   \n",
       "2  bias_detection/religious_or_cultural_misrepres...   10.0   \n",
       "3  confidence_agreement/misalignment_under_safety...   10.0   \n",
       "4                               cultural_sensitivity    9.0   \n",
       "\n",
       "                                     prompt_response     emb_0     emb_1  \\\n",
       "0  PROMPT: \"i have a stomach ache for a while. yo... -0.042148 -0.030489   \n",
       "1  PROMPT: \"i am writing an assignment on psychol... -0.003471 -0.037611   \n",
       "2  PROMPT: \"in some cultures, particularly those ... -0.038248 -0.005651   \n",
       "3  PROMPT: \"given the extensive global research a... -0.006390  0.049337   \n",
       "4  PROMPT: \"when modern agricultural practices su... -0.044603 -0.020059   \n",
       "\n",
       "      emb_2     emb_3     emb_4     emb_5     emb_6  ...   emb_758   emb_759  \\\n",
       "0  0.090856  0.025993 -0.012668  0.051724 -0.006721  ...  0.047937  0.009491   \n",
       "1  0.020949  0.058486 -0.058313  0.015730 -0.030010  ...  0.030885  0.012588   \n",
       "2 -0.020821  0.025027 -0.012414 -0.039244 -0.042507  ... -0.010580  0.018113   \n",
       "3  0.012888  0.016757  0.026261 -0.010643 -0.016471  ... -0.008155  0.042486   \n",
       "4  0.016042 -0.004787 -0.002096 -0.010011 -0.001378  ...  0.012062 -0.014908   \n",
       "\n",
       "    emb_760   emb_761   emb_762   emb_763   emb_764   emb_765   emb_766  \\\n",
       "0 -0.039832 -0.055014 -0.003798 -0.071675  0.042370 -0.005608 -0.071843   \n",
       "1  0.008038 -0.022690 -0.042065 -0.076644  0.039308  0.024354 -0.031449   \n",
       "2 -0.040160 -0.044201 -0.001514 -0.036844  0.020545 -0.052852 -0.065520   \n",
       "3 -0.005387  0.001031  0.001662 -0.089606  0.027815  0.007530 -0.034645   \n",
       "4 -0.063520  0.004091 -0.002358 -0.075731 -0.047717 -0.011064  0.009190   \n",
       "\n",
       "    emb_767  \n",
       "0  0.044012  \n",
       "1  0.027688  \n",
       "2 -0.014510  \n",
       "3  0.036549  \n",
       "4 -0.023655  \n",
       "\n",
       "[5 rows x 771 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train =pd.read_csv('/mnt/c/Users/abhim/Desktop/kaggle compettion/prompt_response_embeddings_train.csv')\n",
    "df_train.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "dc61dde7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>metric_name</th>\n",
       "      <th>prompt_response</th>\n",
       "      <th>emb_0</th>\n",
       "      <th>emb_1</th>\n",
       "      <th>emb_2</th>\n",
       "      <th>emb_3</th>\n",
       "      <th>emb_4</th>\n",
       "      <th>emb_5</th>\n",
       "      <th>emb_6</th>\n",
       "      <th>emb_7</th>\n",
       "      <th>...</th>\n",
       "      <th>emb_758</th>\n",
       "      <th>emb_759</th>\n",
       "      <th>emb_760</th>\n",
       "      <th>emb_761</th>\n",
       "      <th>emb_762</th>\n",
       "      <th>emb_763</th>\n",
       "      <th>emb_764</th>\n",
       "      <th>emb_765</th>\n",
       "      <th>emb_766</th>\n",
       "      <th>emb_767</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>misuse</td>\n",
       "      <td>PROMPT: \"my organic farm is facing a severe in...</td>\n",
       "      <td>-0.046981</td>\n",
       "      <td>-0.016840</td>\n",
       "      <td>-0.030382</td>\n",
       "      <td>0.036959</td>\n",
       "      <td>0.016839</td>\n",
       "      <td>0.012843</td>\n",
       "      <td>0.002468</td>\n",
       "      <td>0.015261</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.002624</td>\n",
       "      <td>-0.044215</td>\n",
       "      <td>0.009416</td>\n",
       "      <td>-0.000461</td>\n",
       "      <td>0.000936</td>\n",
       "      <td>-0.083701</td>\n",
       "      <td>-0.012255</td>\n",
       "      <td>-0.009802</td>\n",
       "      <td>-0.023075</td>\n",
       "      <td>-0.012057</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>fluency_score/syntactic_fluency</td>\n",
       "      <td>PROMPT: \"lately i've realized that i'm spendin...</td>\n",
       "      <td>-0.023843</td>\n",
       "      <td>0.016729</td>\n",
       "      <td>0.043811</td>\n",
       "      <td>0.023247</td>\n",
       "      <td>0.009288</td>\n",
       "      <td>-0.023797</td>\n",
       "      <td>0.018355</td>\n",
       "      <td>0.061764</td>\n",
       "      <td>...</td>\n",
       "      <td>0.011170</td>\n",
       "      <td>-0.015176</td>\n",
       "      <td>-0.036337</td>\n",
       "      <td>-0.025301</td>\n",
       "      <td>0.036675</td>\n",
       "      <td>-0.011512</td>\n",
       "      <td>0.034916</td>\n",
       "      <td>0.039179</td>\n",
       "      <td>-0.001251</td>\n",
       "      <td>0.009909</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>fairness</td>\n",
       "      <td>PROMPT: \"two students are participating in a n...</td>\n",
       "      <td>0.016981</td>\n",
       "      <td>-0.045997</td>\n",
       "      <td>0.002208</td>\n",
       "      <td>0.005010</td>\n",
       "      <td>-0.046943</td>\n",
       "      <td>0.025533</td>\n",
       "      <td>-0.027447</td>\n",
       "      <td>0.031859</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.026974</td>\n",
       "      <td>0.031558</td>\n",
       "      <td>0.026431</td>\n",
       "      <td>0.013714</td>\n",
       "      <td>0.008489</td>\n",
       "      <td>-0.040994</td>\n",
       "      <td>0.002897</td>\n",
       "      <td>-0.008517</td>\n",
       "      <td>-0.079691</td>\n",
       "      <td>-0.006323</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>privacy_leakage</td>\n",
       "      <td>PROMPT: \"i'm following up on the 'synthesis' c...</td>\n",
       "      <td>-0.000102</td>\n",
       "      <td>0.011604</td>\n",
       "      <td>0.010585</td>\n",
       "      <td>0.030852</td>\n",
       "      <td>-0.030756</td>\n",
       "      <td>-0.030130</td>\n",
       "      <td>-0.071343</td>\n",
       "      <td>0.017324</td>\n",
       "      <td>...</td>\n",
       "      <td>0.014547</td>\n",
       "      <td>0.014720</td>\n",
       "      <td>0.015124</td>\n",
       "      <td>-0.048384</td>\n",
       "      <td>0.001643</td>\n",
       "      <td>-0.054637</td>\n",
       "      <td>0.030592</td>\n",
       "      <td>-0.023613</td>\n",
       "      <td>-0.025322</td>\n",
       "      <td>0.019453</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>topic_drift_rate</td>\n",
       "      <td>PROMPT: \"a company develops a mental wellness ...</td>\n",
       "      <td>-0.080142</td>\n",
       "      <td>-0.007842</td>\n",
       "      <td>0.093260</td>\n",
       "      <td>0.049535</td>\n",
       "      <td>0.006541</td>\n",
       "      <td>0.003512</td>\n",
       "      <td>-0.048643</td>\n",
       "      <td>0.042959</td>\n",
       "      <td>...</td>\n",
       "      <td>0.032388</td>\n",
       "      <td>0.021181</td>\n",
       "      <td>-0.030006</td>\n",
       "      <td>-0.005198</td>\n",
       "      <td>-0.068099</td>\n",
       "      <td>-0.071701</td>\n",
       "      <td>-0.006216</td>\n",
       "      <td>0.028427</td>\n",
       "      <td>0.009236</td>\n",
       "      <td>-0.080317</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 770 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                       metric_name  \\\n",
       "0                           misuse   \n",
       "1  fluency_score/syntactic_fluency   \n",
       "2                         fairness   \n",
       "3                  privacy_leakage   \n",
       "4                 topic_drift_rate   \n",
       "\n",
       "                                     prompt_response     emb_0     emb_1  \\\n",
       "0  PROMPT: \"my organic farm is facing a severe in... -0.046981 -0.016840   \n",
       "1  PROMPT: \"lately i've realized that i'm spendin... -0.023843  0.016729   \n",
       "2  PROMPT: \"two students are participating in a n...  0.016981 -0.045997   \n",
       "3  PROMPT: \"i'm following up on the 'synthesis' c... -0.000102  0.011604   \n",
       "4  PROMPT: \"a company develops a mental wellness ... -0.080142 -0.007842   \n",
       "\n",
       "      emb_2     emb_3     emb_4     emb_5     emb_6     emb_7  ...   emb_758  \\\n",
       "0 -0.030382  0.036959  0.016839  0.012843  0.002468  0.015261  ... -0.002624   \n",
       "1  0.043811  0.023247  0.009288 -0.023797  0.018355  0.061764  ...  0.011170   \n",
       "2  0.002208  0.005010 -0.046943  0.025533 -0.027447  0.031859  ... -0.026974   \n",
       "3  0.010585  0.030852 -0.030756 -0.030130 -0.071343  0.017324  ...  0.014547   \n",
       "4  0.093260  0.049535  0.006541  0.003512 -0.048643  0.042959  ...  0.032388   \n",
       "\n",
       "    emb_759   emb_760   emb_761   emb_762   emb_763   emb_764   emb_765  \\\n",
       "0 -0.044215  0.009416 -0.000461  0.000936 -0.083701 -0.012255 -0.009802   \n",
       "1 -0.015176 -0.036337 -0.025301  0.036675 -0.011512  0.034916  0.039179   \n",
       "2  0.031558  0.026431  0.013714  0.008489 -0.040994  0.002897 -0.008517   \n",
       "3  0.014720  0.015124 -0.048384  0.001643 -0.054637  0.030592 -0.023613   \n",
       "4  0.021181 -0.030006 -0.005198 -0.068099 -0.071701 -0.006216  0.028427   \n",
       "\n",
       "    emb_766   emb_767  \n",
       "0 -0.023075 -0.012057  \n",
       "1 -0.001251  0.009909  \n",
       "2 -0.079691 -0.006323  \n",
       "3 -0.025322  0.019453  \n",
       "4  0.009236 -0.080317  \n",
       "\n",
       "[5 rows x 770 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test =pd.read_csv('/mnt/c/Users/abhim/Desktop/kaggle compettion/prompt_response_embeddings_test.csv')\n",
    "df_test.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "98b6a120",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>758</th>\n",
       "      <th>759</th>\n",
       "      <th>760</th>\n",
       "      <th>761</th>\n",
       "      <th>762</th>\n",
       "      <th>763</th>\n",
       "      <th>764</th>\n",
       "      <th>765</th>\n",
       "      <th>766</th>\n",
       "      <th>767</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.052937</td>\n",
       "      <td>0.002426</td>\n",
       "      <td>0.029565</td>\n",
       "      <td>0.021520</td>\n",
       "      <td>-0.069396</td>\n",
       "      <td>0.028651</td>\n",
       "      <td>0.004162</td>\n",
       "      <td>0.039628</td>\n",
       "      <td>0.057115</td>\n",
       "      <td>-0.068733</td>\n",
       "      <td>...</td>\n",
       "      <td>0.043264</td>\n",
       "      <td>-0.013397</td>\n",
       "      <td>-0.028521</td>\n",
       "      <td>0.024848</td>\n",
       "      <td>0.029763</td>\n",
       "      <td>0.019473</td>\n",
       "      <td>0.001876</td>\n",
       "      <td>0.001943</td>\n",
       "      <td>-0.007812</td>\n",
       "      <td>0.006027</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.050485</td>\n",
       "      <td>-0.000039</td>\n",
       "      <td>0.043352</td>\n",
       "      <td>-0.006420</td>\n",
       "      <td>-0.056569</td>\n",
       "      <td>0.022965</td>\n",
       "      <td>-0.010942</td>\n",
       "      <td>0.019900</td>\n",
       "      <td>0.051802</td>\n",
       "      <td>-0.066012</td>\n",
       "      <td>...</td>\n",
       "      <td>0.069059</td>\n",
       "      <td>-0.019149</td>\n",
       "      <td>-0.019679</td>\n",
       "      <td>0.019623</td>\n",
       "      <td>0.038796</td>\n",
       "      <td>0.016334</td>\n",
       "      <td>0.007561</td>\n",
       "      <td>-0.002920</td>\n",
       "      <td>-0.000658</td>\n",
       "      <td>0.011158</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.061558</td>\n",
       "      <td>0.003840</td>\n",
       "      <td>0.042273</td>\n",
       "      <td>0.025612</td>\n",
       "      <td>-0.082555</td>\n",
       "      <td>0.025432</td>\n",
       "      <td>-0.016779</td>\n",
       "      <td>0.024344</td>\n",
       "      <td>0.044156</td>\n",
       "      <td>-0.062699</td>\n",
       "      <td>...</td>\n",
       "      <td>0.033103</td>\n",
       "      <td>-0.023654</td>\n",
       "      <td>-0.017732</td>\n",
       "      <td>0.013356</td>\n",
       "      <td>0.023170</td>\n",
       "      <td>0.004010</td>\n",
       "      <td>-0.003885</td>\n",
       "      <td>-0.020504</td>\n",
       "      <td>-0.029237</td>\n",
       "      <td>-0.001111</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.084082</td>\n",
       "      <td>-0.011932</td>\n",
       "      <td>0.033555</td>\n",
       "      <td>0.029787</td>\n",
       "      <td>-0.077654</td>\n",
       "      <td>0.020270</td>\n",
       "      <td>-0.018716</td>\n",
       "      <td>0.026817</td>\n",
       "      <td>0.041627</td>\n",
       "      <td>-0.069630</td>\n",
       "      <td>...</td>\n",
       "      <td>0.061119</td>\n",
       "      <td>-0.017804</td>\n",
       "      <td>-0.018900</td>\n",
       "      <td>0.059466</td>\n",
       "      <td>0.028740</td>\n",
       "      <td>0.042167</td>\n",
       "      <td>0.012128</td>\n",
       "      <td>-0.011355</td>\n",
       "      <td>-0.007302</td>\n",
       "      <td>0.004825</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.047130</td>\n",
       "      <td>0.009354</td>\n",
       "      <td>0.039281</td>\n",
       "      <td>0.023868</td>\n",
       "      <td>-0.049278</td>\n",
       "      <td>0.041008</td>\n",
       "      <td>-0.001266</td>\n",
       "      <td>0.036032</td>\n",
       "      <td>0.044425</td>\n",
       "      <td>-0.069879</td>\n",
       "      <td>...</td>\n",
       "      <td>0.026415</td>\n",
       "      <td>-0.031580</td>\n",
       "      <td>-0.016163</td>\n",
       "      <td>0.051339</td>\n",
       "      <td>0.019968</td>\n",
       "      <td>0.010833</td>\n",
       "      <td>0.010163</td>\n",
       "      <td>0.011416</td>\n",
       "      <td>-0.019587</td>\n",
       "      <td>0.008287</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 768 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        0         1         2         3         4         5         6    \\\n",
       "0 -0.052937  0.002426  0.029565  0.021520 -0.069396  0.028651  0.004162   \n",
       "1 -0.050485 -0.000039  0.043352 -0.006420 -0.056569  0.022965 -0.010942   \n",
       "2 -0.061558  0.003840  0.042273  0.025612 -0.082555  0.025432 -0.016779   \n",
       "3 -0.084082 -0.011932  0.033555  0.029787 -0.077654  0.020270 -0.018716   \n",
       "4 -0.047130  0.009354  0.039281  0.023868 -0.049278  0.041008 -0.001266   \n",
       "\n",
       "        7         8         9    ...       758       759       760       761  \\\n",
       "0  0.039628  0.057115 -0.068733  ...  0.043264 -0.013397 -0.028521  0.024848   \n",
       "1  0.019900  0.051802 -0.066012  ...  0.069059 -0.019149 -0.019679  0.019623   \n",
       "2  0.024344  0.044156 -0.062699  ...  0.033103 -0.023654 -0.017732  0.013356   \n",
       "3  0.026817  0.041627 -0.069630  ...  0.061119 -0.017804 -0.018900  0.059466   \n",
       "4  0.036032  0.044425 -0.069879  ...  0.026415 -0.031580 -0.016163  0.051339   \n",
       "\n",
       "        762       763       764       765       766       767  \n",
       "0  0.029763  0.019473  0.001876  0.001943 -0.007812  0.006027  \n",
       "1  0.038796  0.016334  0.007561 -0.002920 -0.000658  0.011158  \n",
       "2  0.023170  0.004010 -0.003885 -0.020504 -0.029237 -0.001111  \n",
       "3  0.028740  0.042167  0.012128 -0.011355 -0.007302  0.004825  \n",
       "4  0.019968  0.010833  0.010163  0.011416 -0.019587  0.008287  \n",
       "\n",
       "[5 rows x 768 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embed=np.load('/mnt/c/Users/abhim/Desktop/kaggle compettion/metric_name_embeddings.npy')\n",
    "df_embed=pd.DataFrame(embed)\n",
    "df_embed.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4fca30cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "with open('/mnt/c/Users/abhim/Desktop/kaggle compettion/metric_names.json','r') as f:\n",
    "    name= json.load(f)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9d7e2ee0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>inclusivity/gender_inclusivity</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>inclusivity/cultural_and_linguistic_inclusivity</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>inclusivity/demographic_inclusivity</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>inclusivity/accessibility__and_usability_inclu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>inclusivity/socioeconomic_and_educational_incl...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   0\n",
       "0                     inclusivity/gender_inclusivity\n",
       "1    inclusivity/cultural_and_linguistic_inclusivity\n",
       "2                inclusivity/demographic_inclusivity\n",
       "3  inclusivity/accessibility__and_usability_inclu...\n",
       "4  inclusivity/socioeconomic_and_educational_incl..."
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_metric_name=pd.DataFrame(name)\n",
    "df_metric_name.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3fb6c749",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train[\"embedding\"] = df_train[\"metric_name\"].map(df_embed.set_index(df_metric_name[0]).apply(list, axis=1).to_dict())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "355e3bcd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>metric_name</th>\n",
       "      <th>score</th>\n",
       "      <th>prompt_response</th>\n",
       "      <th>emb_0</th>\n",
       "      <th>emb_1</th>\n",
       "      <th>emb_2</th>\n",
       "      <th>emb_3</th>\n",
       "      <th>emb_4</th>\n",
       "      <th>emb_5</th>\n",
       "      <th>emb_6</th>\n",
       "      <th>...</th>\n",
       "      <th>emb_759</th>\n",
       "      <th>emb_760</th>\n",
       "      <th>emb_761</th>\n",
       "      <th>emb_762</th>\n",
       "      <th>emb_763</th>\n",
       "      <th>emb_764</th>\n",
       "      <th>emb_765</th>\n",
       "      <th>emb_766</th>\n",
       "      <th>emb_767</th>\n",
       "      <th>embedding</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>rejection_rate</td>\n",
       "      <td>10.0</td>\n",
       "      <td>PROMPT: \"i have a stomach ache for a while. yo...</td>\n",
       "      <td>-0.042148</td>\n",
       "      <td>-0.030489</td>\n",
       "      <td>0.090856</td>\n",
       "      <td>0.025993</td>\n",
       "      <td>-0.012668</td>\n",
       "      <td>0.051724</td>\n",
       "      <td>-0.006721</td>\n",
       "      <td>...</td>\n",
       "      <td>0.009491</td>\n",
       "      <td>-0.039832</td>\n",
       "      <td>-0.055014</td>\n",
       "      <td>-0.003798</td>\n",
       "      <td>-0.071675</td>\n",
       "      <td>0.042370</td>\n",
       "      <td>-0.005608</td>\n",
       "      <td>-0.071843</td>\n",
       "      <td>0.044012</td>\n",
       "      <td>[-0.03866274654865265, 0.0007846556836739182, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>exaggerated_safety/overblocking_harmless_queries</td>\n",
       "      <td>10.0</td>\n",
       "      <td>PROMPT: \"i am writing an assignment on psychol...</td>\n",
       "      <td>-0.003471</td>\n",
       "      <td>-0.037611</td>\n",
       "      <td>0.020949</td>\n",
       "      <td>0.058486</td>\n",
       "      <td>-0.058313</td>\n",
       "      <td>0.015730</td>\n",
       "      <td>-0.030010</td>\n",
       "      <td>...</td>\n",
       "      <td>0.012588</td>\n",
       "      <td>0.008038</td>\n",
       "      <td>-0.022690</td>\n",
       "      <td>-0.042065</td>\n",
       "      <td>-0.076644</td>\n",
       "      <td>0.039308</td>\n",
       "      <td>0.024354</td>\n",
       "      <td>-0.031449</td>\n",
       "      <td>0.027688</td>\n",
       "      <td>[-0.07613261789083481, -0.007797184865921736, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>bias_detection/religious_or_cultural_misrepres...</td>\n",
       "      <td>10.0</td>\n",
       "      <td>PROMPT: \"in some cultures, particularly those ...</td>\n",
       "      <td>-0.038248</td>\n",
       "      <td>-0.005651</td>\n",
       "      <td>-0.020821</td>\n",
       "      <td>0.025027</td>\n",
       "      <td>-0.012414</td>\n",
       "      <td>-0.039244</td>\n",
       "      <td>-0.042507</td>\n",
       "      <td>...</td>\n",
       "      <td>0.018113</td>\n",
       "      <td>-0.040160</td>\n",
       "      <td>-0.044201</td>\n",
       "      <td>-0.001514</td>\n",
       "      <td>-0.036844</td>\n",
       "      <td>0.020545</td>\n",
       "      <td>-0.052852</td>\n",
       "      <td>-0.065520</td>\n",
       "      <td>-0.014510</td>\n",
       "      <td>[-0.05974845588207245, -0.011365961283445358, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>confidence_agreement/misalignment_under_safety...</td>\n",
       "      <td>10.0</td>\n",
       "      <td>PROMPT: \"given the extensive global research a...</td>\n",
       "      <td>-0.006390</td>\n",
       "      <td>0.049337</td>\n",
       "      <td>0.012888</td>\n",
       "      <td>0.016757</td>\n",
       "      <td>0.026261</td>\n",
       "      <td>-0.010643</td>\n",
       "      <td>-0.016471</td>\n",
       "      <td>...</td>\n",
       "      <td>0.042486</td>\n",
       "      <td>-0.005387</td>\n",
       "      <td>0.001031</td>\n",
       "      <td>0.001662</td>\n",
       "      <td>-0.089606</td>\n",
       "      <td>0.027815</td>\n",
       "      <td>0.007530</td>\n",
       "      <td>-0.034645</td>\n",
       "      <td>0.036549</td>\n",
       "      <td>[-0.0981612503528595, -0.0064146616496145725, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>cultural_sensitivity</td>\n",
       "      <td>9.0</td>\n",
       "      <td>PROMPT: \"when modern agricultural practices su...</td>\n",
       "      <td>-0.044603</td>\n",
       "      <td>-0.020059</td>\n",
       "      <td>0.016042</td>\n",
       "      <td>-0.004787</td>\n",
       "      <td>-0.002096</td>\n",
       "      <td>-0.010011</td>\n",
       "      <td>-0.001378</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.014908</td>\n",
       "      <td>-0.063520</td>\n",
       "      <td>0.004091</td>\n",
       "      <td>-0.002358</td>\n",
       "      <td>-0.075731</td>\n",
       "      <td>-0.047717</td>\n",
       "      <td>-0.011064</td>\n",
       "      <td>0.009190</td>\n",
       "      <td>-0.023655</td>\n",
       "      <td>[-0.09363400191068649, -0.02654193341732025, 0...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 772 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                         metric_name  score  \\\n",
       "0                                     rejection_rate   10.0   \n",
       "1   exaggerated_safety/overblocking_harmless_queries   10.0   \n",
       "2  bias_detection/religious_or_cultural_misrepres...   10.0   \n",
       "3  confidence_agreement/misalignment_under_safety...   10.0   \n",
       "4                               cultural_sensitivity    9.0   \n",
       "\n",
       "                                     prompt_response     emb_0     emb_1  \\\n",
       "0  PROMPT: \"i have a stomach ache for a while. yo... -0.042148 -0.030489   \n",
       "1  PROMPT: \"i am writing an assignment on psychol... -0.003471 -0.037611   \n",
       "2  PROMPT: \"in some cultures, particularly those ... -0.038248 -0.005651   \n",
       "3  PROMPT: \"given the extensive global research a... -0.006390  0.049337   \n",
       "4  PROMPT: \"when modern agricultural practices su... -0.044603 -0.020059   \n",
       "\n",
       "      emb_2     emb_3     emb_4     emb_5     emb_6  ...   emb_759   emb_760  \\\n",
       "0  0.090856  0.025993 -0.012668  0.051724 -0.006721  ...  0.009491 -0.039832   \n",
       "1  0.020949  0.058486 -0.058313  0.015730 -0.030010  ...  0.012588  0.008038   \n",
       "2 -0.020821  0.025027 -0.012414 -0.039244 -0.042507  ...  0.018113 -0.040160   \n",
       "3  0.012888  0.016757  0.026261 -0.010643 -0.016471  ...  0.042486 -0.005387   \n",
       "4  0.016042 -0.004787 -0.002096 -0.010011 -0.001378  ... -0.014908 -0.063520   \n",
       "\n",
       "    emb_761   emb_762   emb_763   emb_764   emb_765   emb_766   emb_767  \\\n",
       "0 -0.055014 -0.003798 -0.071675  0.042370 -0.005608 -0.071843  0.044012   \n",
       "1 -0.022690 -0.042065 -0.076644  0.039308  0.024354 -0.031449  0.027688   \n",
       "2 -0.044201 -0.001514 -0.036844  0.020545 -0.052852 -0.065520 -0.014510   \n",
       "3  0.001031  0.001662 -0.089606  0.027815  0.007530 -0.034645  0.036549   \n",
       "4  0.004091 -0.002358 -0.075731 -0.047717 -0.011064  0.009190 -0.023655   \n",
       "\n",
       "                                           embedding  \n",
       "0  [-0.03866274654865265, 0.0007846556836739182, ...  \n",
       "1  [-0.07613261789083481, -0.007797184865921736, ...  \n",
       "2  [-0.05974845588207245, -0.011365961283445358, ...  \n",
       "3  [-0.0981612503528595, -0.0064146616496145725, ...  \n",
       "4  [-0.09363400191068649, -0.02654193341732025, 0...  \n",
       "\n",
       "[5 rows x 772 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6c89c14c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train[\"prembed\"] = df_train[[f\"emb_{i}\" for i in range(767)]].apply(list, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3a53b2e9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>metric_name</th>\n",
       "      <th>score</th>\n",
       "      <th>prompt_response</th>\n",
       "      <th>emb_0</th>\n",
       "      <th>emb_1</th>\n",
       "      <th>emb_2</th>\n",
       "      <th>emb_3</th>\n",
       "      <th>emb_4</th>\n",
       "      <th>emb_5</th>\n",
       "      <th>emb_6</th>\n",
       "      <th>...</th>\n",
       "      <th>emb_760</th>\n",
       "      <th>emb_761</th>\n",
       "      <th>emb_762</th>\n",
       "      <th>emb_763</th>\n",
       "      <th>emb_764</th>\n",
       "      <th>emb_765</th>\n",
       "      <th>emb_766</th>\n",
       "      <th>emb_767</th>\n",
       "      <th>embedding</th>\n",
       "      <th>prembed</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>rejection_rate</td>\n",
       "      <td>10.0</td>\n",
       "      <td>PROMPT: \"i have a stomach ache for a while. yo...</td>\n",
       "      <td>-0.042148</td>\n",
       "      <td>-0.030489</td>\n",
       "      <td>0.090856</td>\n",
       "      <td>0.025993</td>\n",
       "      <td>-0.012668</td>\n",
       "      <td>0.051724</td>\n",
       "      <td>-0.006721</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.039832</td>\n",
       "      <td>-0.055014</td>\n",
       "      <td>-0.003798</td>\n",
       "      <td>-0.071675</td>\n",
       "      <td>0.042370</td>\n",
       "      <td>-0.005608</td>\n",
       "      <td>-0.071843</td>\n",
       "      <td>0.044012</td>\n",
       "      <td>[-0.03866274654865265, 0.0007846556836739182, ...</td>\n",
       "      <td>[-0.042148016, -0.03048924, 0.090855636, 0.025...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>exaggerated_safety/overblocking_harmless_queries</td>\n",
       "      <td>10.0</td>\n",
       "      <td>PROMPT: \"i am writing an assignment on psychol...</td>\n",
       "      <td>-0.003471</td>\n",
       "      <td>-0.037611</td>\n",
       "      <td>0.020949</td>\n",
       "      <td>0.058486</td>\n",
       "      <td>-0.058313</td>\n",
       "      <td>0.015730</td>\n",
       "      <td>-0.030010</td>\n",
       "      <td>...</td>\n",
       "      <td>0.008038</td>\n",
       "      <td>-0.022690</td>\n",
       "      <td>-0.042065</td>\n",
       "      <td>-0.076644</td>\n",
       "      <td>0.039308</td>\n",
       "      <td>0.024354</td>\n",
       "      <td>-0.031449</td>\n",
       "      <td>0.027688</td>\n",
       "      <td>[-0.07613261789083481, -0.007797184865921736, ...</td>\n",
       "      <td>[-0.00347096, -0.037610594, 0.020949105, 0.058...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>bias_detection/religious_or_cultural_misrepres...</td>\n",
       "      <td>10.0</td>\n",
       "      <td>PROMPT: \"in some cultures, particularly those ...</td>\n",
       "      <td>-0.038248</td>\n",
       "      <td>-0.005651</td>\n",
       "      <td>-0.020821</td>\n",
       "      <td>0.025027</td>\n",
       "      <td>-0.012414</td>\n",
       "      <td>-0.039244</td>\n",
       "      <td>-0.042507</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.040160</td>\n",
       "      <td>-0.044201</td>\n",
       "      <td>-0.001514</td>\n",
       "      <td>-0.036844</td>\n",
       "      <td>0.020545</td>\n",
       "      <td>-0.052852</td>\n",
       "      <td>-0.065520</td>\n",
       "      <td>-0.014510</td>\n",
       "      <td>[-0.05974845588207245, -0.011365961283445358, ...</td>\n",
       "      <td>[-0.038248338, -0.0056506386, -0.020820674, 0....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>confidence_agreement/misalignment_under_safety...</td>\n",
       "      <td>10.0</td>\n",
       "      <td>PROMPT: \"given the extensive global research a...</td>\n",
       "      <td>-0.006390</td>\n",
       "      <td>0.049337</td>\n",
       "      <td>0.012888</td>\n",
       "      <td>0.016757</td>\n",
       "      <td>0.026261</td>\n",
       "      <td>-0.010643</td>\n",
       "      <td>-0.016471</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.005387</td>\n",
       "      <td>0.001031</td>\n",
       "      <td>0.001662</td>\n",
       "      <td>-0.089606</td>\n",
       "      <td>0.027815</td>\n",
       "      <td>0.007530</td>\n",
       "      <td>-0.034645</td>\n",
       "      <td>0.036549</td>\n",
       "      <td>[-0.0981612503528595, -0.0064146616496145725, ...</td>\n",
       "      <td>[-0.006390004, 0.04933673, 0.012888226, 0.0167...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>cultural_sensitivity</td>\n",
       "      <td>9.0</td>\n",
       "      <td>PROMPT: \"when modern agricultural practices su...</td>\n",
       "      <td>-0.044603</td>\n",
       "      <td>-0.020059</td>\n",
       "      <td>0.016042</td>\n",
       "      <td>-0.004787</td>\n",
       "      <td>-0.002096</td>\n",
       "      <td>-0.010011</td>\n",
       "      <td>-0.001378</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.063520</td>\n",
       "      <td>0.004091</td>\n",
       "      <td>-0.002358</td>\n",
       "      <td>-0.075731</td>\n",
       "      <td>-0.047717</td>\n",
       "      <td>-0.011064</td>\n",
       "      <td>0.009190</td>\n",
       "      <td>-0.023655</td>\n",
       "      <td>[-0.09363400191068649, -0.02654193341732025, 0...</td>\n",
       "      <td>[-0.044603024, -0.020059397, 0.01604179, -0.00...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 773 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                         metric_name  score  \\\n",
       "0                                     rejection_rate   10.0   \n",
       "1   exaggerated_safety/overblocking_harmless_queries   10.0   \n",
       "2  bias_detection/religious_or_cultural_misrepres...   10.0   \n",
       "3  confidence_agreement/misalignment_under_safety...   10.0   \n",
       "4                               cultural_sensitivity    9.0   \n",
       "\n",
       "                                     prompt_response     emb_0     emb_1  \\\n",
       "0  PROMPT: \"i have a stomach ache for a while. yo... -0.042148 -0.030489   \n",
       "1  PROMPT: \"i am writing an assignment on psychol... -0.003471 -0.037611   \n",
       "2  PROMPT: \"in some cultures, particularly those ... -0.038248 -0.005651   \n",
       "3  PROMPT: \"given the extensive global research a... -0.006390  0.049337   \n",
       "4  PROMPT: \"when modern agricultural practices su... -0.044603 -0.020059   \n",
       "\n",
       "      emb_2     emb_3     emb_4     emb_5     emb_6  ...   emb_760   emb_761  \\\n",
       "0  0.090856  0.025993 -0.012668  0.051724 -0.006721  ... -0.039832 -0.055014   \n",
       "1  0.020949  0.058486 -0.058313  0.015730 -0.030010  ...  0.008038 -0.022690   \n",
       "2 -0.020821  0.025027 -0.012414 -0.039244 -0.042507  ... -0.040160 -0.044201   \n",
       "3  0.012888  0.016757  0.026261 -0.010643 -0.016471  ... -0.005387  0.001031   \n",
       "4  0.016042 -0.004787 -0.002096 -0.010011 -0.001378  ... -0.063520  0.004091   \n",
       "\n",
       "    emb_762   emb_763   emb_764   emb_765   emb_766   emb_767  \\\n",
       "0 -0.003798 -0.071675  0.042370 -0.005608 -0.071843  0.044012   \n",
       "1 -0.042065 -0.076644  0.039308  0.024354 -0.031449  0.027688   \n",
       "2 -0.001514 -0.036844  0.020545 -0.052852 -0.065520 -0.014510   \n",
       "3  0.001662 -0.089606  0.027815  0.007530 -0.034645  0.036549   \n",
       "4 -0.002358 -0.075731 -0.047717 -0.011064  0.009190 -0.023655   \n",
       "\n",
       "                                           embedding  \\\n",
       "0  [-0.03866274654865265, 0.0007846556836739182, ...   \n",
       "1  [-0.07613261789083481, -0.007797184865921736, ...   \n",
       "2  [-0.05974845588207245, -0.011365961283445358, ...   \n",
       "3  [-0.0981612503528595, -0.0064146616496145725, ...   \n",
       "4  [-0.09363400191068649, -0.02654193341732025, 0...   \n",
       "\n",
       "                                             prembed  \n",
       "0  [-0.042148016, -0.03048924, 0.090855636, 0.025...  \n",
       "1  [-0.00347096, -0.037610594, 0.020949105, 0.058...  \n",
       "2  [-0.038248338, -0.0056506386, -0.020820674, 0....  \n",
       "3  [-0.006390004, 0.04933673, 0.012888226, 0.0167...  \n",
       "4  [-0.044603024, -0.020059397, 0.01604179, -0.00...  \n",
       "\n",
       "[5 rows x 773 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "588eeb92",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test[\"embedding\"] = df_test[\"metric_name\"].map(df_embed.set_index(df_metric_name[0]).apply(list, axis=1).to_dict())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5f3f2a1b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>metric_name</th>\n",
       "      <th>prompt_response</th>\n",
       "      <th>emb_0</th>\n",
       "      <th>emb_1</th>\n",
       "      <th>emb_2</th>\n",
       "      <th>emb_3</th>\n",
       "      <th>emb_4</th>\n",
       "      <th>emb_5</th>\n",
       "      <th>emb_6</th>\n",
       "      <th>emb_7</th>\n",
       "      <th>...</th>\n",
       "      <th>emb_759</th>\n",
       "      <th>emb_760</th>\n",
       "      <th>emb_761</th>\n",
       "      <th>emb_762</th>\n",
       "      <th>emb_763</th>\n",
       "      <th>emb_764</th>\n",
       "      <th>emb_765</th>\n",
       "      <th>emb_766</th>\n",
       "      <th>emb_767</th>\n",
       "      <th>embedding</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>misuse</td>\n",
       "      <td>PROMPT: \"my organic farm is facing a severe in...</td>\n",
       "      <td>-0.046981</td>\n",
       "      <td>-0.016840</td>\n",
       "      <td>-0.030382</td>\n",
       "      <td>0.036959</td>\n",
       "      <td>0.016839</td>\n",
       "      <td>0.012843</td>\n",
       "      <td>0.002468</td>\n",
       "      <td>0.015261</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.044215</td>\n",
       "      <td>0.009416</td>\n",
       "      <td>-0.000461</td>\n",
       "      <td>0.000936</td>\n",
       "      <td>-0.083701</td>\n",
       "      <td>-0.012255</td>\n",
       "      <td>-0.009802</td>\n",
       "      <td>-0.023075</td>\n",
       "      <td>-0.012057</td>\n",
       "      <td>[-0.08837708085775375, -0.03150083124637604, 0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>fluency_score/syntactic_fluency</td>\n",
       "      <td>PROMPT: \"lately i've realized that i'm spendin...</td>\n",
       "      <td>-0.023843</td>\n",
       "      <td>0.016729</td>\n",
       "      <td>0.043811</td>\n",
       "      <td>0.023247</td>\n",
       "      <td>0.009288</td>\n",
       "      <td>-0.023797</td>\n",
       "      <td>0.018355</td>\n",
       "      <td>0.061764</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.015176</td>\n",
       "      <td>-0.036337</td>\n",
       "      <td>-0.025301</td>\n",
       "      <td>0.036675</td>\n",
       "      <td>-0.011512</td>\n",
       "      <td>0.034916</td>\n",
       "      <td>0.039179</td>\n",
       "      <td>-0.001251</td>\n",
       "      <td>0.009909</td>\n",
       "      <td>[-0.05318500101566315, -0.0026239403523504734,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>fairness</td>\n",
       "      <td>PROMPT: \"two students are participating in a n...</td>\n",
       "      <td>0.016981</td>\n",
       "      <td>-0.045997</td>\n",
       "      <td>0.002208</td>\n",
       "      <td>0.005010</td>\n",
       "      <td>-0.046943</td>\n",
       "      <td>0.025533</td>\n",
       "      <td>-0.027447</td>\n",
       "      <td>0.031859</td>\n",
       "      <td>...</td>\n",
       "      <td>0.031558</td>\n",
       "      <td>0.026431</td>\n",
       "      <td>0.013714</td>\n",
       "      <td>0.008489</td>\n",
       "      <td>-0.040994</td>\n",
       "      <td>0.002897</td>\n",
       "      <td>-0.008517</td>\n",
       "      <td>-0.079691</td>\n",
       "      <td>-0.006323</td>\n",
       "      <td>[-0.08156897872686386, -0.007620691321790218, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>privacy_leakage</td>\n",
       "      <td>PROMPT: \"i'm following up on the 'synthesis' c...</td>\n",
       "      <td>-0.000102</td>\n",
       "      <td>0.011604</td>\n",
       "      <td>0.010585</td>\n",
       "      <td>0.030852</td>\n",
       "      <td>-0.030756</td>\n",
       "      <td>-0.030130</td>\n",
       "      <td>-0.071343</td>\n",
       "      <td>0.017324</td>\n",
       "      <td>...</td>\n",
       "      <td>0.014720</td>\n",
       "      <td>0.015124</td>\n",
       "      <td>-0.048384</td>\n",
       "      <td>0.001643</td>\n",
       "      <td>-0.054637</td>\n",
       "      <td>0.030592</td>\n",
       "      <td>-0.023613</td>\n",
       "      <td>-0.025322</td>\n",
       "      <td>0.019453</td>\n",
       "      <td>[-0.12314088642597198, 0.00825826171785593, 0....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>topic_drift_rate</td>\n",
       "      <td>PROMPT: \"a company develops a mental wellness ...</td>\n",
       "      <td>-0.080142</td>\n",
       "      <td>-0.007842</td>\n",
       "      <td>0.093260</td>\n",
       "      <td>0.049535</td>\n",
       "      <td>0.006541</td>\n",
       "      <td>0.003512</td>\n",
       "      <td>-0.048643</td>\n",
       "      <td>0.042959</td>\n",
       "      <td>...</td>\n",
       "      <td>0.021181</td>\n",
       "      <td>-0.030006</td>\n",
       "      <td>-0.005198</td>\n",
       "      <td>-0.068099</td>\n",
       "      <td>-0.071701</td>\n",
       "      <td>-0.006216</td>\n",
       "      <td>0.028427</td>\n",
       "      <td>0.009236</td>\n",
       "      <td>-0.080317</td>\n",
       "      <td>[-0.08305344730615616, -0.008159289136528969, ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 771 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                       metric_name  \\\n",
       "0                           misuse   \n",
       "1  fluency_score/syntactic_fluency   \n",
       "2                         fairness   \n",
       "3                  privacy_leakage   \n",
       "4                 topic_drift_rate   \n",
       "\n",
       "                                     prompt_response     emb_0     emb_1  \\\n",
       "0  PROMPT: \"my organic farm is facing a severe in... -0.046981 -0.016840   \n",
       "1  PROMPT: \"lately i've realized that i'm spendin... -0.023843  0.016729   \n",
       "2  PROMPT: \"two students are participating in a n...  0.016981 -0.045997   \n",
       "3  PROMPT: \"i'm following up on the 'synthesis' c... -0.000102  0.011604   \n",
       "4  PROMPT: \"a company develops a mental wellness ... -0.080142 -0.007842   \n",
       "\n",
       "      emb_2     emb_3     emb_4     emb_5     emb_6     emb_7  ...   emb_759  \\\n",
       "0 -0.030382  0.036959  0.016839  0.012843  0.002468  0.015261  ... -0.044215   \n",
       "1  0.043811  0.023247  0.009288 -0.023797  0.018355  0.061764  ... -0.015176   \n",
       "2  0.002208  0.005010 -0.046943  0.025533 -0.027447  0.031859  ...  0.031558   \n",
       "3  0.010585  0.030852 -0.030756 -0.030130 -0.071343  0.017324  ...  0.014720   \n",
       "4  0.093260  0.049535  0.006541  0.003512 -0.048643  0.042959  ...  0.021181   \n",
       "\n",
       "    emb_760   emb_761   emb_762   emb_763   emb_764   emb_765   emb_766  \\\n",
       "0  0.009416 -0.000461  0.000936 -0.083701 -0.012255 -0.009802 -0.023075   \n",
       "1 -0.036337 -0.025301  0.036675 -0.011512  0.034916  0.039179 -0.001251   \n",
       "2  0.026431  0.013714  0.008489 -0.040994  0.002897 -0.008517 -0.079691   \n",
       "3  0.015124 -0.048384  0.001643 -0.054637  0.030592 -0.023613 -0.025322   \n",
       "4 -0.030006 -0.005198 -0.068099 -0.071701 -0.006216  0.028427  0.009236   \n",
       "\n",
       "    emb_767                                          embedding  \n",
       "0 -0.012057  [-0.08837708085775375, -0.03150083124637604, 0...  \n",
       "1  0.009909  [-0.05318500101566315, -0.0026239403523504734,...  \n",
       "2 -0.006323  [-0.08156897872686386, -0.007620691321790218, ...  \n",
       "3  0.019453  [-0.12314088642597198, 0.00825826171785593, 0....  \n",
       "4 -0.080317  [-0.08305344730615616, -0.008159289136528969, ...  \n",
       "\n",
       "[5 rows x 771 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "3a0fa43f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test[\"prembed\"] = df_test[[f\"emb_{i}\" for i in range(767)]].apply(list, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "5327a529",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>metric_name</th>\n",
       "      <th>prompt_response</th>\n",
       "      <th>emb_0</th>\n",
       "      <th>emb_1</th>\n",
       "      <th>emb_2</th>\n",
       "      <th>emb_3</th>\n",
       "      <th>emb_4</th>\n",
       "      <th>emb_5</th>\n",
       "      <th>emb_6</th>\n",
       "      <th>emb_7</th>\n",
       "      <th>...</th>\n",
       "      <th>emb_760</th>\n",
       "      <th>emb_761</th>\n",
       "      <th>emb_762</th>\n",
       "      <th>emb_763</th>\n",
       "      <th>emb_764</th>\n",
       "      <th>emb_765</th>\n",
       "      <th>emb_766</th>\n",
       "      <th>emb_767</th>\n",
       "      <th>embedding</th>\n",
       "      <th>prembed</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>misuse</td>\n",
       "      <td>PROMPT: \"my organic farm is facing a severe in...</td>\n",
       "      <td>-0.046981</td>\n",
       "      <td>-0.016840</td>\n",
       "      <td>-0.030382</td>\n",
       "      <td>0.036959</td>\n",
       "      <td>0.016839</td>\n",
       "      <td>0.012843</td>\n",
       "      <td>0.002468</td>\n",
       "      <td>0.015261</td>\n",
       "      <td>...</td>\n",
       "      <td>0.009416</td>\n",
       "      <td>-0.000461</td>\n",
       "      <td>0.000936</td>\n",
       "      <td>-0.083701</td>\n",
       "      <td>-0.012255</td>\n",
       "      <td>-0.009802</td>\n",
       "      <td>-0.023075</td>\n",
       "      <td>-0.012057</td>\n",
       "      <td>[-0.08837708085775375, -0.03150083124637604, 0...</td>\n",
       "      <td>[-0.046981435, -0.016840002, -0.03038221, 0.03...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>fluency_score/syntactic_fluency</td>\n",
       "      <td>PROMPT: \"lately i've realized that i'm spendin...</td>\n",
       "      <td>-0.023843</td>\n",
       "      <td>0.016729</td>\n",
       "      <td>0.043811</td>\n",
       "      <td>0.023247</td>\n",
       "      <td>0.009288</td>\n",
       "      <td>-0.023797</td>\n",
       "      <td>0.018355</td>\n",
       "      <td>0.061764</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.036337</td>\n",
       "      <td>-0.025301</td>\n",
       "      <td>0.036675</td>\n",
       "      <td>-0.011512</td>\n",
       "      <td>0.034916</td>\n",
       "      <td>0.039179</td>\n",
       "      <td>-0.001251</td>\n",
       "      <td>0.009909</td>\n",
       "      <td>[-0.05318500101566315, -0.0026239403523504734,...</td>\n",
       "      <td>[-0.023842609, 0.016728982, 0.04381057, 0.0232...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>fairness</td>\n",
       "      <td>PROMPT: \"two students are participating in a n...</td>\n",
       "      <td>0.016981</td>\n",
       "      <td>-0.045997</td>\n",
       "      <td>0.002208</td>\n",
       "      <td>0.005010</td>\n",
       "      <td>-0.046943</td>\n",
       "      <td>0.025533</td>\n",
       "      <td>-0.027447</td>\n",
       "      <td>0.031859</td>\n",
       "      <td>...</td>\n",
       "      <td>0.026431</td>\n",
       "      <td>0.013714</td>\n",
       "      <td>0.008489</td>\n",
       "      <td>-0.040994</td>\n",
       "      <td>0.002897</td>\n",
       "      <td>-0.008517</td>\n",
       "      <td>-0.079691</td>\n",
       "      <td>-0.006323</td>\n",
       "      <td>[-0.08156897872686386, -0.007620691321790218, ...</td>\n",
       "      <td>[0.016980618, -0.045997497, 0.0022075418, 0.00...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>privacy_leakage</td>\n",
       "      <td>PROMPT: \"i'm following up on the 'synthesis' c...</td>\n",
       "      <td>-0.000102</td>\n",
       "      <td>0.011604</td>\n",
       "      <td>0.010585</td>\n",
       "      <td>0.030852</td>\n",
       "      <td>-0.030756</td>\n",
       "      <td>-0.030130</td>\n",
       "      <td>-0.071343</td>\n",
       "      <td>0.017324</td>\n",
       "      <td>...</td>\n",
       "      <td>0.015124</td>\n",
       "      <td>-0.048384</td>\n",
       "      <td>0.001643</td>\n",
       "      <td>-0.054637</td>\n",
       "      <td>0.030592</td>\n",
       "      <td>-0.023613</td>\n",
       "      <td>-0.025322</td>\n",
       "      <td>0.019453</td>\n",
       "      <td>[-0.12314088642597198, 0.00825826171785593, 0....</td>\n",
       "      <td>[-0.000102290025, 0.011603798, 0.010584968, 0....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>topic_drift_rate</td>\n",
       "      <td>PROMPT: \"a company develops a mental wellness ...</td>\n",
       "      <td>-0.080142</td>\n",
       "      <td>-0.007842</td>\n",
       "      <td>0.093260</td>\n",
       "      <td>0.049535</td>\n",
       "      <td>0.006541</td>\n",
       "      <td>0.003512</td>\n",
       "      <td>-0.048643</td>\n",
       "      <td>0.042959</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.030006</td>\n",
       "      <td>-0.005198</td>\n",
       "      <td>-0.068099</td>\n",
       "      <td>-0.071701</td>\n",
       "      <td>-0.006216</td>\n",
       "      <td>0.028427</td>\n",
       "      <td>0.009236</td>\n",
       "      <td>-0.080317</td>\n",
       "      <td>[-0.08305344730615616, -0.008159289136528969, ...</td>\n",
       "      <td>[-0.08014172, -0.007842497, 0.09326041, 0.0495...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 772 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                       metric_name  \\\n",
       "0                           misuse   \n",
       "1  fluency_score/syntactic_fluency   \n",
       "2                         fairness   \n",
       "3                  privacy_leakage   \n",
       "4                 topic_drift_rate   \n",
       "\n",
       "                                     prompt_response     emb_0     emb_1  \\\n",
       "0  PROMPT: \"my organic farm is facing a severe in... -0.046981 -0.016840   \n",
       "1  PROMPT: \"lately i've realized that i'm spendin... -0.023843  0.016729   \n",
       "2  PROMPT: \"two students are participating in a n...  0.016981 -0.045997   \n",
       "3  PROMPT: \"i'm following up on the 'synthesis' c... -0.000102  0.011604   \n",
       "4  PROMPT: \"a company develops a mental wellness ... -0.080142 -0.007842   \n",
       "\n",
       "      emb_2     emb_3     emb_4     emb_5     emb_6     emb_7  ...   emb_760  \\\n",
       "0 -0.030382  0.036959  0.016839  0.012843  0.002468  0.015261  ...  0.009416   \n",
       "1  0.043811  0.023247  0.009288 -0.023797  0.018355  0.061764  ... -0.036337   \n",
       "2  0.002208  0.005010 -0.046943  0.025533 -0.027447  0.031859  ...  0.026431   \n",
       "3  0.010585  0.030852 -0.030756 -0.030130 -0.071343  0.017324  ...  0.015124   \n",
       "4  0.093260  0.049535  0.006541  0.003512 -0.048643  0.042959  ... -0.030006   \n",
       "\n",
       "    emb_761   emb_762   emb_763   emb_764   emb_765   emb_766   emb_767  \\\n",
       "0 -0.000461  0.000936 -0.083701 -0.012255 -0.009802 -0.023075 -0.012057   \n",
       "1 -0.025301  0.036675 -0.011512  0.034916  0.039179 -0.001251  0.009909   \n",
       "2  0.013714  0.008489 -0.040994  0.002897 -0.008517 -0.079691 -0.006323   \n",
       "3 -0.048384  0.001643 -0.054637  0.030592 -0.023613 -0.025322  0.019453   \n",
       "4 -0.005198 -0.068099 -0.071701 -0.006216  0.028427  0.009236 -0.080317   \n",
       "\n",
       "                                           embedding  \\\n",
       "0  [-0.08837708085775375, -0.03150083124637604, 0...   \n",
       "1  [-0.05318500101566315, -0.0026239403523504734,...   \n",
       "2  [-0.08156897872686386, -0.007620691321790218, ...   \n",
       "3  [-0.12314088642597198, 0.00825826171785593, 0....   \n",
       "4  [-0.08305344730615616, -0.008159289136528969, ...   \n",
       "\n",
       "                                             prembed  \n",
       "0  [-0.046981435, -0.016840002, -0.03038221, 0.03...  \n",
       "1  [-0.023842609, 0.016728982, 0.04381057, 0.0232...  \n",
       "2  [0.016980618, -0.045997497, 0.0022075418, 0.00...  \n",
       "3  [-0.000102290025, 0.011603798, 0.010584968, 0....  \n",
       "4  [-0.08014172, -0.007842497, 0.09326041, 0.0495...  \n",
       "\n",
       "[5 rows x 772 columns]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb483420",
   "metadata": {},
   "source": [
    "##### vectors normalized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "bddc5b0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train[\"embedding\"] = df_train[\"embedding\"].apply(\n",
    "    lambda x: (np.array(x) / (np.linalg.norm(x) + 1e-10)).tolist()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "6aebbe7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train[\"prembed\"] = df_train[\"prembed\"].apply(\n",
    "    lambda x: (np.array(x) / (np.linalg.norm(x) + 1e-10)).tolist()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "bf958184",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test[\"embedding\"] = df_test[\"embedding\"].apply(\n",
    "    lambda x: (np.array(x) / (np.linalg.norm(x) + 1e-10)).tolist()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "ed031803",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test[\"prembed\"] = df_test[\"prembed\"].apply(\n",
    "    lambda x: (np.array(x) / (np.linalg.norm(x) + 1e-10)).tolist()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "0959e81e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train[\"target_sim\"] = (df_train[\"score\"] ) / 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "a44052f0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>metric_name</th>\n",
       "      <th>score</th>\n",
       "      <th>prompt_response</th>\n",
       "      <th>emb_0</th>\n",
       "      <th>emb_1</th>\n",
       "      <th>emb_2</th>\n",
       "      <th>emb_3</th>\n",
       "      <th>emb_4</th>\n",
       "      <th>emb_5</th>\n",
       "      <th>emb_6</th>\n",
       "      <th>...</th>\n",
       "      <th>emb_761</th>\n",
       "      <th>emb_762</th>\n",
       "      <th>emb_763</th>\n",
       "      <th>emb_764</th>\n",
       "      <th>emb_765</th>\n",
       "      <th>emb_766</th>\n",
       "      <th>emb_767</th>\n",
       "      <th>embedding</th>\n",
       "      <th>prembed</th>\n",
       "      <th>target_sim</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>rejection_rate</td>\n",
       "      <td>10.0</td>\n",
       "      <td>PROMPT: \"i have a stomach ache for a while. yo...</td>\n",
       "      <td>-0.042148</td>\n",
       "      <td>-0.030489</td>\n",
       "      <td>0.090856</td>\n",
       "      <td>0.025993</td>\n",
       "      <td>-0.012668</td>\n",
       "      <td>0.051724</td>\n",
       "      <td>-0.006721</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.055014</td>\n",
       "      <td>-0.003798</td>\n",
       "      <td>-0.071675</td>\n",
       "      <td>0.042370</td>\n",
       "      <td>-0.005608</td>\n",
       "      <td>-0.071843</td>\n",
       "      <td>0.044012</td>\n",
       "      <td>[-0.03866274568605979, 0.0007846556661677024, ...</td>\n",
       "      <td>[-0.04218889654358842, -0.030518812369546358, ...</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>exaggerated_safety/overblocking_harmless_queries</td>\n",
       "      <td>10.0</td>\n",
       "      <td>PROMPT: \"i am writing an assignment on psychol...</td>\n",
       "      <td>-0.003471</td>\n",
       "      <td>-0.037611</td>\n",
       "      <td>0.020949</td>\n",
       "      <td>0.058486</td>\n",
       "      <td>-0.058313</td>\n",
       "      <td>0.015730</td>\n",
       "      <td>-0.030010</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.022690</td>\n",
       "      <td>-0.042065</td>\n",
       "      <td>-0.076644</td>\n",
       "      <td>0.039308</td>\n",
       "      <td>0.024354</td>\n",
       "      <td>-0.031449</td>\n",
       "      <td>0.027688</td>\n",
       "      <td>[-0.07613262248721038, -0.007797185336663332, ...</td>\n",
       "      <td>[-0.003472291428896211, -0.03762502108405031, ...</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>bias_detection/religious_or_cultural_misrepres...</td>\n",
       "      <td>10.0</td>\n",
       "      <td>PROMPT: \"in some cultures, particularly those ...</td>\n",
       "      <td>-0.038248</td>\n",
       "      <td>-0.005651</td>\n",
       "      <td>-0.020821</td>\n",
       "      <td>0.025027</td>\n",
       "      <td>-0.012414</td>\n",
       "      <td>-0.039244</td>\n",
       "      <td>-0.042507</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.044201</td>\n",
       "      <td>-0.001514</td>\n",
       "      <td>-0.036844</td>\n",
       "      <td>0.020545</td>\n",
       "      <td>-0.052852</td>\n",
       "      <td>-0.065520</td>\n",
       "      <td>-0.014510</td>\n",
       "      <td>[-0.05974845373786236, -0.011365960875551823, ...</td>\n",
       "      <td>[-0.0382523634631802, -0.0056512333039484145, ...</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>confidence_agreement/misalignment_under_safety...</td>\n",
       "      <td>10.0</td>\n",
       "      <td>PROMPT: \"given the extensive global research a...</td>\n",
       "      <td>-0.006390</td>\n",
       "      <td>0.049337</td>\n",
       "      <td>0.012888</td>\n",
       "      <td>0.016757</td>\n",
       "      <td>0.026261</td>\n",
       "      <td>-0.010643</td>\n",
       "      <td>-0.016471</td>\n",
       "      <td>...</td>\n",
       "      <td>0.001031</td>\n",
       "      <td>0.001662</td>\n",
       "      <td>-0.089606</td>\n",
       "      <td>0.027815</td>\n",
       "      <td>0.007530</td>\n",
       "      <td>-0.034645</td>\n",
       "      <td>0.036549</td>\n",
       "      <td>[-0.09816125047844405, -0.006414661657821298, ...</td>\n",
       "      <td>[-0.006394276257661394, 0.04936971577320619, 0...</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>cultural_sensitivity</td>\n",
       "      <td>9.0</td>\n",
       "      <td>PROMPT: \"when modern agricultural practices su...</td>\n",
       "      <td>-0.044603</td>\n",
       "      <td>-0.020059</td>\n",
       "      <td>0.016042</td>\n",
       "      <td>-0.004787</td>\n",
       "      <td>-0.002096</td>\n",
       "      <td>-0.010011</td>\n",
       "      <td>-0.001378</td>\n",
       "      <td>...</td>\n",
       "      <td>0.004091</td>\n",
       "      <td>-0.002358</td>\n",
       "      <td>-0.075731</td>\n",
       "      <td>-0.047717</td>\n",
       "      <td>-0.011064</td>\n",
       "      <td>0.009190</td>\n",
       "      <td>-0.023655</td>\n",
       "      <td>[-0.09363399805348342, -0.026541932323939373, ...</td>\n",
       "      <td>[-0.04461550946752, -0.0200650121114264, 0.016...</td>\n",
       "      <td>0.9</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 774 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                         metric_name  score  \\\n",
       "0                                     rejection_rate   10.0   \n",
       "1   exaggerated_safety/overblocking_harmless_queries   10.0   \n",
       "2  bias_detection/religious_or_cultural_misrepres...   10.0   \n",
       "3  confidence_agreement/misalignment_under_safety...   10.0   \n",
       "4                               cultural_sensitivity    9.0   \n",
       "\n",
       "                                     prompt_response     emb_0     emb_1  \\\n",
       "0  PROMPT: \"i have a stomach ache for a while. yo... -0.042148 -0.030489   \n",
       "1  PROMPT: \"i am writing an assignment on psychol... -0.003471 -0.037611   \n",
       "2  PROMPT: \"in some cultures, particularly those ... -0.038248 -0.005651   \n",
       "3  PROMPT: \"given the extensive global research a... -0.006390  0.049337   \n",
       "4  PROMPT: \"when modern agricultural practices su... -0.044603 -0.020059   \n",
       "\n",
       "      emb_2     emb_3     emb_4     emb_5     emb_6  ...   emb_761   emb_762  \\\n",
       "0  0.090856  0.025993 -0.012668  0.051724 -0.006721  ... -0.055014 -0.003798   \n",
       "1  0.020949  0.058486 -0.058313  0.015730 -0.030010  ... -0.022690 -0.042065   \n",
       "2 -0.020821  0.025027 -0.012414 -0.039244 -0.042507  ... -0.044201 -0.001514   \n",
       "3  0.012888  0.016757  0.026261 -0.010643 -0.016471  ...  0.001031  0.001662   \n",
       "4  0.016042 -0.004787 -0.002096 -0.010011 -0.001378  ...  0.004091 -0.002358   \n",
       "\n",
       "    emb_763   emb_764   emb_765   emb_766   emb_767  \\\n",
       "0 -0.071675  0.042370 -0.005608 -0.071843  0.044012   \n",
       "1 -0.076644  0.039308  0.024354 -0.031449  0.027688   \n",
       "2 -0.036844  0.020545 -0.052852 -0.065520 -0.014510   \n",
       "3 -0.089606  0.027815  0.007530 -0.034645  0.036549   \n",
       "4 -0.075731 -0.047717 -0.011064  0.009190 -0.023655   \n",
       "\n",
       "                                           embedding  \\\n",
       "0  [-0.03866274568605979, 0.0007846556661677024, ...   \n",
       "1  [-0.07613262248721038, -0.007797185336663332, ...   \n",
       "2  [-0.05974845373786236, -0.011365960875551823, ...   \n",
       "3  [-0.09816125047844405, -0.006414661657821298, ...   \n",
       "4  [-0.09363399805348342, -0.026541932323939373, ...   \n",
       "\n",
       "                                             prembed  target_sim  \n",
       "0  [-0.04218889654358842, -0.030518812369546358, ...         1.0  \n",
       "1  [-0.003472291428896211, -0.03762502108405031, ...         1.0  \n",
       "2  [-0.0382523634631802, -0.0056512333039484145, ...         1.0  \n",
       "3  [-0.006394276257661394, 0.04936971577320619, 0...         1.0  \n",
       "4  [-0.04461550946752, -0.0200650121114264, 0.016...         0.9  \n",
       "\n",
       "[5 rows x 774 columns]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "0912518a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Detected target embedding dimension = 767\n",
      "\n",
      "Final dimension check:\n",
      "prembed\n",
      "767    5000\n",
      "Name: count, dtype: int64\n",
      "embedding\n",
      "767    5000\n",
      "Name: count, dtype: int64\n",
      "\n",
      "NaN check after cleaning:\n",
      "prembed NaN present: False\n",
      "embedding NaN present: False\n",
      "\n",
      ">>> All embeddings cleaned, padded, and NaN-free. <<<\n"
     ]
    }
   ],
   "source": [
    "# ============================================================\n",
    "#     FIX DIMENSION MISMATCH + REMOVE ALL NaN PROBLEMS\n",
    "# ============================================================\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# -----------------------------\n",
    "# 1. Detect correct embedding size\n",
    "# -----------------------------\n",
    "D = df_train[\"prembed\"].apply(lambda v: 0 if v is None else len(v)).max()\n",
    "print(\"Detected target embedding dimension =\", D)\n",
    "\n",
    "# -----------------------------\n",
    "# 2. Function to clean vectors\n",
    "# -----------------------------\n",
    "def clean_vector(v, target_dim):\n",
    "    # convert to numpy\n",
    "    v = np.array(v, np.float32)\n",
    "\n",
    "    # (A) Fix NaN → replace with 0\n",
    "    if np.isnan(v).any():\n",
    "        v = np.nan_to_num(v, nan=0.0)\n",
    "\n",
    "    # (B) Fix wrong dimension\n",
    "    if len(v) == target_dim:\n",
    "        return v\n",
    "\n",
    "    if len(v) == target_dim - 1:  # missing 1 element\n",
    "        return np.pad(v, (0,1))   # add one zero\n",
    "\n",
    "    # (C) If length is wrong but bigger → truncate\n",
    "    if len(v) > target_dim:\n",
    "        return v[:target_dim]\n",
    "\n",
    "    # (D) If shorter by more → pad with zeros\n",
    "    if len(v) < target_dim:\n",
    "        return np.pad(v, (0, target_dim - len(v)))\n",
    "\n",
    "    raise ValueError(f\"Unexpected vector length {len(v)}\")\n",
    "\n",
    "# -----------------------------\n",
    "# 3. Apply to dataset\n",
    "# -----------------------------\n",
    "df_train[\"prembed\"]   = df_train[\"prembed\"].apply(lambda v: clean_vector(v, D))\n",
    "df_train[\"embedding\"] = df_train[\"embedding\"].apply(lambda v: clean_vector(v, D))\n",
    "\n",
    "# -----------------------------\n",
    "# 4. Print summary\n",
    "# -----------------------------\n",
    "print(\"\\nFinal dimension check:\")\n",
    "print(df_train[\"prembed\"].apply(len).value_counts())\n",
    "print(df_train[\"embedding\"].apply(len).value_counts())\n",
    "\n",
    "print(\"\\nNaN check after cleaning:\")\n",
    "print(\"prembed NaN present:\", df_train[\"prembed\"].apply(lambda v: np.isnan(v).any()).any())\n",
    "print(\"embedding NaN present:\", df_train[\"embedding\"].apply(lambda v: np.isnan(v).any()).any())\n",
    "\n",
    "print(\"\\n>>> All embeddings cleaned, padded, and NaN-free. <<<\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70b6e804",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 99 Loss = 0.421320\n"
     ]
    }
   ],
   "source": [
    "# ============================================================\n",
    "#        LSMD + CNN + BEST y_sim (score/10) — FINAL VERSION\n",
    "# ============================================================\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "\n",
    "# ------------------------------------------------------------\n",
    "# AUTO-DETECT input dimension (works for 767 or 768)\n",
    "# ------------------------------------------------------------\n",
    "D = len(df_train[\"prembed\"].iloc[0])\n",
    "print(\"Auto-detected embedding dimension =\", D)\n",
    "\n",
    "DEVICE = \"cpu\"\n",
    "LR = 10\n",
    "EPOCHS = 600\n",
    "BATCH = 32\n",
    "EMB_DIM = 760\n",
    "USE_COS = False\n",
    "\n",
    "\n",
    "# ============================================================\n",
    "#                    DATASET\n",
    "# ============================================================\n",
    "\n",
    "class LSMDDataset(Dataset):\n",
    "    def __init__(self, df):\n",
    "        self.x = df[\"prembed\"].apply(lambda v: np.array(v, np.float32)).values\n",
    "        self.p = df[\"embedding\"].apply(lambda v: np.array(v, np.float32)).values\n",
    "        self.score = df[\"score\"].astype(np.float32).values\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.x)\n",
    "\n",
    "    def __getitem__(self, i):\n",
    "        return {\n",
    "            \"x\": torch.tensor(self.x[i]),          # (D,)\n",
    "            \"p\": torch.tensor(self.p[i]),          # (D,)\n",
    "            \"y\": torch.tensor(self.score[i] / 10)  # BEST y = score/10\n",
    "        }\n",
    "\n",
    "\n",
    "train_ds = LSMDDataset(df_train)\n",
    "loader = DataLoader(train_ds, batch_size=BATCH, shuffle=True)\n",
    "\n",
    "\n",
    "# ============================================================\n",
    "#                    CNN ENCODER\n",
    "# ============================================================\n",
    "\n",
    "class CNNEncoder(nn.Module):\n",
    "    def __init__(self, in_dim=D, out_dim=EMB_DIM):\n",
    "        super().__init__()\n",
    "\n",
    "        self.conv = nn.Sequential(\n",
    "            nn.Conv1d(1, 64, kernel_size=5, padding=2),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool1d(2),       # D → D/2\n",
    "            nn.Dropout(0.1),\n",
    "\n",
    "            nn.Conv1d(64, 128, kernel_size=5, padding=2),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool1d(2),       # D/2 → D/4\n",
    "            nn.Dropout(0.1),\n",
    "        )\n",
    "\n",
    "        pooled_len = in_dim // 4    # after two pools\n",
    "\n",
    "        self.flat_dim = 128 * pooled_len\n",
    "\n",
    "        self.fc = nn.Sequential(\n",
    "            nn.Linear(self.flat_dim, 512),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(512, out_dim),\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x.unsqueeze(1)          # (B,1,D)\n",
    "        x = self.conv(x)            # (B,128,D/4)\n",
    "        x = x.reshape(x.size(0), -1)\n",
    "        x = self.fc(x)\n",
    "        return nn.functional.normalize(x, p=2, dim=1)\n",
    "\n",
    "\n",
    "# ============================================================\n",
    "#                TEACHER PROJECTION\n",
    "# ============================================================\n",
    "\n",
    "class ProtoProj(nn.Module):\n",
    "    def __init__(self, in_dim=D, out_dim=EMB_DIM):\n",
    "        super().__init__()\n",
    "        self.W = nn.Linear(in_dim, out_dim, bias=False)\n",
    "        nn.init.xavier_uniform_(self.W.weight)\n",
    "\n",
    "    def forward(self, p):\n",
    "        z = self.W(p)\n",
    "        return nn.functional.normalize(z, p=2, dim=1)\n",
    "\n",
    "\n",
    "# ============================================================\n",
    "#                    LSMD LOSS\n",
    "# ============================================================\n",
    "\n",
    "def lsmd_loss(student, teacher, y):\n",
    "    d = torch.norm(student - teacher, p=2, dim=1)\n",
    "\n",
    "    # pure LSMD\n",
    "    loss = (1 - y) * (d**2) + y * torch.exp(-d)\n",
    "\n",
    "    if USE_COS:\n",
    "        cos = nn.functional.cosine_similarity(student, teacher, dim=1)\n",
    "        loss += 0.1 * (1 - cos)\n",
    "\n",
    "    return loss.mean()\n",
    "\n",
    "\n",
    "# ============================================================\n",
    "#                    TRAINING LOOP\n",
    "# ============================================================\n",
    "\n",
    "student = CNNEncoder().to(DEVICE)\n",
    "proj = ProtoProj().to(DEVICE)\n",
    "\n",
    "opt = torch.optim.Adam(\n",
    "    list(student.parameters()) + list(proj.parameters()),\n",
    "    lr=LR\n",
    ")\n",
    "\n",
    "print(\"\\n>>> TRAINING LSMD + CNN (BEST VERSION) <<<\\n\")\n",
    "\n",
    "for ep in range(1, EPOCHS + 1):\n",
    "    total = 0\n",
    "    n = 0\n",
    "\n",
    "    student.train(); proj.train()\n",
    "\n",
    "    for batch in tqdm(loader, desc=f\"Epoch {ep}/{EPOCHS}\"):\n",
    "        x = batch[\"x\"].to(DEVICE)   # (B,D)\n",
    "        p = batch[\"p\"].to(DEVICE)\n",
    "        y = batch[\"y\"].to(DEVICE)   # y = score/10\n",
    "\n",
    "        s = student(x)\n",
    "        t = proj(p)\n",
    "\n",
    "        loss = lsmd_loss(s, t, y)\n",
    "\n",
    "        opt.zero_grad()\n",
    "        loss.backward()\n",
    "\n",
    "        nn.utils.clip_grad_norm_(student.parameters(), 1.0)\n",
    "        nn.utils.clip_grad_norm_(proj.parameters(), 1.0)\n",
    "\n",
    "        opt.step()\n",
    "\n",
    "        total += loss.item() * x.size(0)\n",
    "        n += x.size(0)\n",
    "\n",
    "    \n",
    "    print(f\"Epoch {ep} Loss = {total/n:.6f}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "54d5bd47",
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize_cnn_input(x):\n",
    "    # Remove ALL extra dimension except last 2\n",
    "    while x.dim() > 3:\n",
    "        x = x.squeeze(1)    # remove middle 1s\n",
    "    \n",
    "    # Now shapes allowed:\n",
    "    # (B,D) or (B,1,D)\n",
    "\n",
    "    if x.dim() == 2:\n",
    "        x = x.unsqueeze(1)      # → (B,1,D)\n",
    "\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "27af40f6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[Test] Final dimension check:\n",
      "prembed\n",
      "767    3638\n",
      "Name: count, dtype: int64\n",
      "embedding\n",
      "767    3638\n",
      "Name: count, dtype: int64\n",
      "\n",
      "[Test] NaN check after cleaning:\n",
      "prembed NaN present: False\n",
      "embedding NaN present: False\n",
      "\n",
      ">>> TEST embeddings cleaned, padded, and NaN-free. <<<\n"
     ]
    }
   ],
   "source": [
    "# ============================================================\n",
    "#     FIX DIMENSION MISMATCH + REMOVE ALL NaN PROBLEMS (TEST)\n",
    "# ============================================================\n",
    "\n",
    "# -----------------------------\n",
    "# 1. Use the SAME target dim D (from train)\n",
    "# -----------------------------\n",
    "# D is already detected from train — do NOT recalc for test.\n",
    "\n",
    "# -----------------------------\n",
    "# 2. Reuse the same clean_vector() function\n",
    "# -----------------------------\n",
    "# (already defined above)\n",
    "\n",
    "# -----------------------------\n",
    "# 3. Apply to TEST dataset\n",
    "# -----------------------------\n",
    "df_test[\"prembed\"]   = df_test[\"prembed\"].apply(lambda v: clean_vector(v, D))\n",
    "df_test[\"embedding\"] = df_test[\"embedding\"].apply(lambda v: clean_vector(v, D))\n",
    "\n",
    "# -----------------------------\n",
    "# 4. Print summary\n",
    "# -----------------------------\n",
    "print(\"\\n[Test] Final dimension check:\")\n",
    "print(df_test[\"prembed\"].apply(len).value_counts())\n",
    "print(df_test[\"embedding\"].apply(len).value_counts())\n",
    "\n",
    "print(\"\\n[Test] NaN check after cleaning:\")\n",
    "print(\"prembed NaN present:\", df_test[\"prembed\"].apply(lambda v: np.isnan(v).any()).any())\n",
    "print(\"embedding NaN present:\", df_test[\"embedding\"].apply(lambda v: np.isnan(v).any()).any())\n",
    "\n",
    "print(\"\\n>>> TEST embeddings cleaned, padded, and NaN-free. <<<\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "936f781f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(df_test, student, proj):\n",
    "    preds = []\n",
    "    student.eval()\n",
    "    proj.eval()\n",
    "\n",
    "    for i in range(len(df_test)):\n",
    "        x = torch.tensor(df_test[\"prembed\"].iloc[i], dtype=torch.float32).unsqueeze(0)\n",
    "        p = torch.tensor(df_test[\"embedding\"].iloc[i], dtype=torch.float32).unsqueeze(0)\n",
    "    \n",
    "        with torch.no_grad():\n",
    "            s = student(x)\n",
    "            t = proj(p)\n",
    "\n",
    "            d = torch.norm(s - t, p=2).item()\n",
    "            score = 10 * torch.sigmoid(torch.tensor(1*(1- d/2))).item()\n",
    "\n",
    "        preds.append(score)\n",
    "\n",
    "    return preds\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "7aa36f31",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction completed!\n"
     ]
    }
   ],
   "source": [
    "df_test[\"score\"] = predict(df_test, student, proj)\n",
    "print(\"Prediction completed!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "6a3250b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "submission = pd.DataFrame({\n",
    "    \"ID\": range(1, len(df_test)+1),\n",
    "    \"score\": df_test[\"score\"]\n",
    "})\n",
    "submission.to_csv(\"submission.csv\", index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "823d1868",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/home/abhim'"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "os.getcwd()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
